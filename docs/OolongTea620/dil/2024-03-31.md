# 9장 웹 크롤러 설계



### 역할

- 검색 엔진에서 널리 쓰이는 기술
- 웹에 새로 배우거나 갱신된 콘텐츠를 찾아내는 것

### 특징

**웹 크롤러의 복잡도는 웹 크롤러가 처리해야하는 데이터의 규모에 따라서 달라진다.**

설계할 웹 크롤러가 감당을 해야하는 **`데이터 규모`와 `기능`을 최우선으로 고려해야 한다**.

### 이용 부분

#### 검색 엔진 인덱싱(search engine indexing)

웹페이지를 모아서 검색 엔진을 위한 로컬 인덱스(local index)   

ex\) 구글의 Googlebot - 구글 검색 엔진이 사용하는 웹 크롤러 

#### 웹 아카이빙(Web archiving)

나중에 사용할 목적으로 장기보관하기 위해 웹에서 정보를 모으는 절차   
많은 국립 도서관들이 크롤러를 돌려서 웹 사이트를 아카이빙 중   

ex\) 미국 국회 도서관(US Libary of Congress), EU, 웹 아카이브

#### 웹 마이닝(web mining)

웹 마이닝을 통해서 인터넷에서 유용한 지식을 도출해 낼 수 있는 것

```
금융 기업의 경우, 크롤러를 사용하여 주주 총 회 자료나 연차 보고서(annual report)를 다운받아서 기업의 핵심 사업 방향을 알아내기도 한다.
```

#### 웹 모니터링(web monitoring)

크롤러를 사용하면 인터넷에서 저작권이나 상표권이 침해되는 사례를 모니터링 할 수 있다.

```
디지마크(digimark)사의 경우, 웹 크롤러를 사용하여 해적파 저작물을 찾아내서 보고한다.
```

## 1단계 - 문제 이해 및 설계 범위 확정

웹 크롤러의 알고리즘
```
1. URL 집합이 입력으로 주어지면, 해당 URL들이 가리키는 모든 웹 페이지를 다운로드 한다.

2. 다운받은 웹 페이지에서  URL들을 호출한다.

3. 추출된 URL들을 다운로드할 URL 목록에 추가하고 위의 과정을 처음부터 반복한다.
```

**..의문점 : 이렇게 단순하게 동작할까?🤔**


### (책에서의) 요구사항

```
- 주된 용도 : 검색엔진 인덱싱
- 수집되는 웹페이지의 규모 : 10억개 정도(1 bilion) 웹페이지 수집
- 새로 만들어지거나, 수정된 웹페이지도 고려
- 5년간 저장 필요
- 중복된 콘텐츠의 경우는 무시한다고 가정
```

### 웹 크롤러 구현시 고려할 주요 속성

- 규모 확장성 : 웹에는 수십억개의 페이지가 존재. 병행성(paralleism)을 활용하는 보다 효과적으로 웹 크롤링을 할 수 있다.

- 안정성(robustness) : 비정상적인 입력이나 환경에 잘 대응할 수 있어야 한다(잘못 작성된 HTML, 아무 반응 없는 서버, 장애 악성코드가 있는 링크...) 

- 예절(politeness) : 크롤러는 수집 대상 웹 사이트에 짧은 시간 동안 너무 많은 요청을 보내서는 안된다.

- 확장성(extensibility) : 새로운 형태의 콘텐츠를 지원하기 쉬워야 한다.(이미지 파일 추가 수집 시, 전체 시스템 설계를 다시 할 필요가 없다고 가정)

### 개략적인 규모 추정

```
- 매달 10억개의 웹 페이지 다운로드
- QPS = 10억(1 bilion) /30일 /24 시간/ 3600 초 = 400 페이지/초
- 최대(Peak) QPS = 2 X QPS = 800
- 웹 페이지의 평균 크기는 500kb라고 가정
- 10억 페이지 x 500kb = 500TB/월 
- 1개월치 500TB를 5년 보관 가정, 결국 500TB x 12개월 x 5년 = 30PB의 저장용량 필요
```

## 2단계 - 개략적인 설계안 제시 및 동의 구하기

![대략적 설계안](https://velog.velcdn.com/images/kyy00n/post/7b970245-ec85-4421-b3f1-d4809034737d/image.png)

### 시작 URL 집합

웹 크롤러가 크롤링을 시작하는 출발점.

> 어떤 대학 웹 사이트로부터 찾아 나설 수 있는 모든 웹 페이지를 크롤링하는 가장 직관적인 방법 : 
> 해당 대학의 도메인 이름이 붙은 모든 페이지의 URL을 시작하는 것이다.

- 전체 웹을 크롤링하는 경우, 시작 URL을 고르는데 장의적일 필요가 있다.
  - 크롤러는 가능한 한 많은 링크를 탐색할 수 있도록 하는 URL을 고를 필요성이 있다.
- 전체 URL 공간을 작은 부분 집합으로 나누는 전략을 사용
  - 지역적인 특색, 나라별로 인기있는 웹 사이트는 다르다
  
- 주제별로 다른 시작 URL을 사용하는 것
  - URL 공간을 쇼핑, 스포츠 건강 등등에 주제별로 세분화 그 각각에 다른 시작 URL을 사용하는 것

### 미수집 URL 저장소

웹 크롤러의 크롤링 상대


1. 다운로드할 URL 
2. 다운로드 될 URL : `미수집 URL 저장소`라는 컴포넌트가 관리

#### 미수집 URL 저장소(URL Frontier)
👉 **3단계 상세 설계 링크로 바로가기**

FIFO Queue


#### HTML 다운로더

#### 도메인 이름 변환기

#### 콘텐츠 파서

#### 중복 콘텐츠 인가?

#### 콘텐츠 저장소

#### 콘텐츠 저장소
#### URL 추출기
#### URL 필터
#### 이미 방문한 URL
#### URL 저장소
#### 웹 크롤러 작업 흐름

