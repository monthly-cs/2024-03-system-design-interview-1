# 15장 구글 드라이브 설계

## 1단계 - 문제 이해 및 설계 범위 확정

```
- 파일 업로드/다운로드, 파일 동기화, 알림

- 웹/모바일 앱 지원
- 파일 암호화 필요
- 사용자 당 10 GB 제한
- DAU : (10,000,000) 천만 사용자 
```

### 집중할 기능

```
- 클라이언트에서 drag-and-drop 방식의 파일 추가 
- 파일 다운로드
- 여러 단말의 파일 동기화
- 파일 갱신 이력 조회
- 파일 공유
- 파일이 편집, 삭제되거나 새롭게 공유될 시, 알림 표시
```

### 논의하지 않을 기능

```
- 구글 문서 편집 및 협업
```

### 비-기능적 요구 사항

- 안정성 : 데이터 손실이 발생하면 안된다.
- 빠른 동기화 속도 : 파일 동기화 시, 사용자가 기다림을 느끼면 안된다.
- 네트워크 대역폭 : 낭비를 해서는 안된다.(모바일 환경 사용자에게도 중요한 부분)
- 규모 확장성 : 아주 많은 양의 트래픽도 처리 가능해야 한다.
- 높은 가용성 : 일부 서버에 장애 발생하거나, 느려지거나, 네트워크 일부가 끊겨도 시스템은 계속 사용해야 한다.

### 개략적 추정치

- 가입 사용자는 5000만명, DAU 1000만명.
- 모든 사용자에게 10GB의 저장 공간 할당
- 매일 각 사용자가 평균 2개의 파일을 업로드 한다고 가정. 각 파일의 평균 크기는 500KB
- 읽기: 쓰기 비율을 1 : 1
- 필요한 저장 공간 총량 = 5000만 사용자 X 10 GB = **500 PB**
- 업로드 API QPS = 1천만 사용자 x 2회 업로드/ 24 시간 / 3600 초 == 약 240
- 최대 QPS = QPS x 2 = 480

## 2단계 - 개략적 설계안 제시 및 동의 구하기

> _모든 것을 담은 한 대 서버에서 시작해서 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜 나가는 것으로 서술_

- 파일을 올리고 다운로드 하는 과정을 처리할 앱 서버
- 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 데이터베이스
- 파일을 저장할 저장소 시스템 : 파일 저장을 위해서 1TB의 공간을 사용할 것

```
/drive
    /user1
        /recipes
            checken_soup.txt
    /user2
        football.mov
        sports.txt
    /user3
        best_pic_ever.png
```

### API 
#### 모든 API 공통 사항

```
- 사용자 인증을 필요로 한다.
- HTTPS 프로토콜을 사용한다 : 클라이언트와 백엔드 서버가 주고받는 데이터 보호하기 위한 것
```


#### 파일 업로드 API 

👉 두 종류의 업로드를 지원

- 단순 업로드 : 파일 크기가 작을 때 사용

- 이어 올리기 : 파일 사이즈가 크고, 네트워크 문제로 업로드가 중단될 가능성이 높다고 생각되면 사용

**인자**   
- uploadType=resumable
- data: 업로드할 로컬 파일

이어올리기 절차
1. 이어올리기 URL을 받기 위한 최초 요청 전송
2. 데이터를 업로드하고 업로드 상태 모니터링
3. 업로드에 장애가 발생하면 장애 발생 시점부터 업로드를 재시작

#### 파일 다운로드 API 

ex) https://api.example.com/files/download

**인자**  
- path: 다운로드할 파일의 경로

**예**  
{
    "path" : "/recipes/soup/best_soup.txt"  
}

#### 파일 갱신 히스토리 API

ex) https://api.example.com/files/list_revisions

**인자**
- path: 갱신 히스토리를 가져올 파일의 경로
- limit: 히스토리 길이의 최대치

**예**
{
    "path" : "/recipes/soup/best_soup.txt",
    limit: 20
}

### 한 대 서버의 제약 극복

> /drive 용량이 가득 찬다면..?


🤔 데이터 샤딩을 해야할까?   
> 특정 서버가 꺼지면 해당 서버 데이터 손실에 대한 고민은 여전하다.

Amazon S3(Simple Storage Service)를 사용하는 것을 어떤가?
> S3는 다중화를 지원한다.
> 동일지역 내 다중화, 여러 지역에 걸칠 다중화 지원

파일을 S3를 이용하여 관리하기로 결정

#### 추가 적인 개선 사항

1. 로그밸런서 : 네트워크 트래픽을 분산하기 위해 로드밸런서 사용
```
네트워크 트래픽을 분산하기 위해서 로드밸런서를 사용.
트래픽을 고르게 분산 시키고, 특정 웹 서버에 장애가 발생하면 자동적으로 해당 서버를 우회해준다.
```

2. 웹 서버 : 로드밸런서를 추가 뒤 더 많은 웹 서비스를 손쉽게 추가할 수 있다.

더 많은 트래픽이 폭증해도 쉽게 대응이 가능

3. 메타데이터 데이터베이스
- 데이터베이스를 파일 저장 서버에서 분리 -> SPOF를 회피
- 다중화 및 샤딩 정책을 적용, 가용성과 규모 확장성 요구사항에 대응

4. 파일 저장소 : S3를 파일 저장소로 사용하고, 가용성과 데이터 무손실을 보장하기 위해서 두 개 이상의 지역에 데이터를 다중화 한다.

### 동기화 충돌

구글 드라이브 같은 대형 저장소 시스템의 경우, 간혹 동기화 충돌이 발생가능하다.
(두 명이상의 사용자가 같은 파일이나 폴더를 동시에 업데이트하려고 하는 경우)

#### 동기화 충돌 해소 전략

1. 먼저 처리되는 변경은 성공한 것으로 가정하고, 
2. 나중에 처리되는 변경은 충돌이 발생한 것으로 표시

#### [4],[5] 참고